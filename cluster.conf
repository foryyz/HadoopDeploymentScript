# ============================================================
# Hadoop 3.x 完全分布式集群配置文件（Ubuntu 24 + VMware）
# 适配脚本：
#   sc_1.sh  - 系统前置（网络 / SSH / 主机名 / 克隆修复）
#   sc_2.sh  - Hadoop 安装 + 配置 + 分发（不含 format/start）
# ============================================================


# =========================
# 基础用户配置
# =========================
HADOOP_USER="hadoop"
HADOOP_GROUP="hadoop"
TIMEZONE="Asia/Shanghai"


# =========================
# 网络配置（VMware）
# =========================
# VMware 虚拟网络编辑器中设置的网段
NET_PREFIX="192.168.120"
NET_CIDR="24"

# 网关地址（以 VMware NAT/Host-only 实际值为准）
GATEWAY="192.168.120.2"

# DNS（可多个）
DNS_SERVERS=("114.114.114.114" "8.8.8.8")


# =========================
# IP 规划（默认）
# 可在 sc_1.sh 执行时用 --ip 覆盖
# =========================
DEFAULT_IP_MASTER="192.168.120.10"
DEFAULT_IP_WORKER1="192.168.120.11"
DEFAULT_IP_WORKER2="192.168.120.12"


# =========================
# 主机名规划（可随时修改）
# =========================
MASTER_HOSTNAME="master"
WORKER1_HOSTNAME="worker1"
WORKER2_HOSTNAME="worker2"


# =========================
# 集群角色规划
# =========================
# master:
#   - NameNode
#   - ResourceManager
#   - JobHistoryServer
#
# worker1:
#   - DataNode
#   - NodeManager
#   - SecondaryNameNode
#
# worker2:
#   - DataNode
#   - NodeManager

ENABLE_SECONDARY_NAMENODE="true"
SECONDARY_NAMENODE_HOSTNAME="${WORKER1_HOSTNAME}"

ENABLE_JOBHISTORYSERVER="true"
JOBHISTORYSERVER_HOSTNAME="${MASTER_HOSTNAME}"


# =========================
# Hadoop / JDK 下载源
# =========================
JDK_DOWNLOAD_LINK="https://mirrors.tuna.tsinghua.edu.cn/Adoptium/8/jdk/x64/linux/OpenJDK8U-jdk_x64_linux_hotspot_8u472b08.tar.gz"
HADOOP_DOWNLOAD_LINK="https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz"


# =========================
# 安装路径规划
# =========================
# 推荐：程序与数据分离
INSTALL_BASE="/opt"

# Java 安装目录
JAVA_DIR="${INSTALL_BASE}/jdk8"

# Hadoop 版本目录（实际安装目录）
HADOOP_DIR="${INSTALL_BASE}/hadoop"

# Hadoop 当前版本软链接（方便升级）
HADOOP_SYMLINK="${INSTALL_BASE}/hadoop-current"


# =========================
# Hadoop 数据目录
# =========================
HADOOP_DATA_DIR="/data/hadoop"

HDFS_NAME_DIR="${HADOOP_DATA_DIR}/namenode"
HDFS_DATA_DIR="${HADOOP_DATA_DIR}/datanode"


# =========================
# Hadoop 核心参数
# =========================
FS_DEFAULT_PORT="9000"

# 只有 2 个 DataNode，必须是 2
HDFS_REPLICATION="2"


# =========================
# MapReduce JobHistoryServer
# =========================
MAPREDUCE_JOBHISTORY_ADDRESS_PORT="10020"
MAPREDUCE_JOBHISTORY_WEBAPP_PORT="19888"


# =========================
# SSH / 远程分发策略
# =========================
# sc_2.sh 使用 root@worker 分发文件
# copy-id  : 执行时手动输入 root 密码（推荐）
# sshpass  : 全自动（教学环境可用）
SSH_PUSH_MODE="copy-id"

# 仅当 SSH_PUSH_MODE=sshpass 时需要
SSH_DEFAULT_PASSWORD="hadoop"


# =========================
# Root SSH 支持（关键）
# =========================
# Ubuntu 默认 root 无密码，且 SSH 禁止 root 登录
# sc_1.sh 会根据以下配置自动处理

ENABLE_ROOT_SSH="true"

# true  = 允许 root 使用密码登录（用于首次推 key）
# false = 只允许 root 使用密钥登录
ROOT_SSH_PASSWORD_AUTH="true"

# root 默认密码（Ubuntu 必须设置，否则无法 ssh-copy-id）
# ⚠ 教学/实验环境可用，生产环境不推荐
ROOT_DEFAULT_PASSWORD="hadoop"


# =========================
# VMware 克隆修复
# =========================
# 修复 machine-id 与 SSH host key 冲突
FIX_CLONE_IDENTITY="true"


# =========================
# Netplan / Ubuntu 网络
# =========================
NETPLAN_RENDERER="networkd"


# =========================
# 集群节点清单（自动生成 hosts / workers）
# =========================
CLUSTER_HOSTNAMES=(
  "${MASTER_HOSTNAME}"
  "${WORKER1_HOSTNAME}"
  "${WORKER2_HOSTNAME}"
)

CLUSTER_IPS=(
  "${DEFAULT_IP_MASTER}"
  "${DEFAULT_IP_WORKER1}"
  "${DEFAULT_IP_WORKER2}"
)
