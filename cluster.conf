# ============================================================
# Hadoop 3.x 完全分布式集群配置文件（Ubuntu 24 + VMware）
# 适配脚本：
#   sc_all.sh  - 系统前置（网络 / SSH / 主机名 / 克隆修复 / 免密准备）
#   sc_master.sh  - Hadoop 安装 + 配置 + 分发（通过 hadoop@worker）
#   run_hadoop.sh  - format/start/health/stop
# ============================================================


# =========================
# 基础用户配置
# =========================
HADOOP_USER="hadoop"
HADOOP_GROUP="hadoop"
TIMEZONE="Asia/Shanghai"


# =========================
# 网络配置（VMware）
# =========================
NET_PREFIX="192.168.120"
NET_CIDR="24"
GATEWAY="192.168.120.2"
DNS_SERVERS=("114.114.114.114" "8.8.8.8")


# =========================
# IP 规划（默认）
# sc_all.sh 不传 --ip 时会读取这里的默认值
# =========================
DEFAULT_IP_MASTER="192.168.120.10"
DEFAULT_IP_WORKER1="192.168.120.11"
DEFAULT_IP_WORKER2="192.168.120.12"


# =========================
# 主机名规划（可随时修改）
# =========================
MASTER_HOSTNAME="master"
WORKER1_HOSTNAME="worker1"
WORKER2_HOSTNAME="worker2"


# =========================
# 集群角色规划
# =========================
ENABLE_SECONDARY_NAMENODE="true"
SECONDARY_NAMENODE_HOSTNAME="${WORKER1_HOSTNAME}"

ENABLE_JOBHISTORYSERVER="true"
JOBHISTORYSERVER_HOSTNAME="${MASTER_HOSTNAME}"


# =========================
# Hadoop / JDK 下载源
# =========================
JDK_DOWNLOAD_LINK="https://mirrors.tuna.tsinghua.edu.cn/Adoptium/8/jdk/x64/linux/OpenJDK8U-jdk_x64_linux_hotspot_8u472b08.tar.gz"
HADOOP_DOWNLOAD_LINK="https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.4.2/hadoop-3.4.2.tar.gz"


# =========================
# 安装路径规划
# =========================
INSTALL_BASE="/opt"
JAVA_DIR="${INSTALL_BASE}/jdk8"
HADOOP_DIR="${INSTALL_BASE}/hadoop"
HADOOP_SYMLINK="${INSTALL_BASE}/hadoop-current"


# =========================
# Hadoop 数据目录
# =========================
HADOOP_DATA_DIR="/data/hadoop"
HDFS_NAME_DIR="${HADOOP_DATA_DIR}/namenode"
HDFS_DATA_DIR="${HADOOP_DATA_DIR}/datanode"


# =========================
# Hadoop 核心参数
# =========================
FS_DEFAULT_PORT="9000"
HDFS_REPLICATION="2"


# =========================
# MapReduce JobHistoryServer
# =========================
MAPREDUCE_JOBHISTORY_ADDRESS_PORT="10020"
MAPREDUCE_JOBHISTORY_WEBAPP_PORT="19888"


# =========================
# SSH / 分发策略（hadoop@worker）
# =========================
# copy-id : 执行时手动输入 worker 上 hadoop 的密码（推荐）
# sshpass : 全自动（教学环境）
SSH_PUSH_MODE="copy-id"

# 仅当 SSH_PUSH_MODE=sshpass 时需要
SSH_DEFAULT_PASSWORD="hadoop"


# =========================
# VMware 克隆修复
# =========================
FIX_CLONE_IDENTITY="true"


# =========================
# Netplan / Ubuntu 网络
# =========================
NETPLAN_RENDERER="networkd"


# =========================
# 集群节点清单（自动生成 hosts / workers）
# =========================
CLUSTER_HOSTNAMES=(
  "${MASTER_HOSTNAME}"
  "${WORKER1_HOSTNAME}"
  "${WORKER2_HOSTNAME}"
)

CLUSTER_IPS=(
  "${DEFAULT_IP_MASTER}"
  "${DEFAULT_IP_WORKER1}"
  "${DEFAULT_IP_WORKER2}"
)


# ============================================================
# Spark (Spark on YARN) 配置
# ============================================================

# Spark 下载（选择预编译 Hadoop3 版本）
SPARK_DOWNLOAD_LINK="https://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-3.5.8/spark-3.5.8-bin-hadoop3.tgz"

# 安装目录
SPARK_DIR="${INSTALL_BASE}/spark"
SPARK_SYMLINK="${INSTALL_BASE}/spark-current"

# Spark 配置文件模板（可扩展）
# Spark on YARN：默认 master=yarn
SPARK_MASTER="yarn"
SPARK_DEPLOY_MODE_DEFAULT="client"   # client / cluster

# Spark 事件日志（建议开启，配合 History Server）
ENABLE_SPARK_EVENTLOG="true"

# 本地事件日志目录（每台机器都要有，用 sc_1 保障 /data 可写亦可；此脚本也会创建）
SPARK_EVENTLOG_DIR_LOCAL="/data/spark/eventlog"

# HDFS 事件日志目录（推荐使用 HDFS，History Server 读它）
# 需要 Hadoop/HDFS 已经起来后创建（本脚本可尝试创建；失败则提示你在 sc_3 start 后再建）
SPARK_EVENTLOG_DIR_HDFS="hdfs:///spark-eventlog"

# Spark History Server（服务部署在 master）
ENABLE_SPARK_HISTORY_SERVER="true"
SPARK_HISTORYSERVER_HOSTNAME="${MASTER_HOSTNAME}"
SPARK_HISTORYSERVER_UI_PORT="18080"

# Spark SQL warehouse（默认会写到当前用户目录，建议放到 HDFS）
SPARK_SQL_WAREHOUSE_DIR="hdfs:///spark-warehouse"

# YARN 相关（可选：不填也能跑）
# SPARK_YARN_QUEUE="default"
# SPARK_YARN_MAXAPPATTEMPTS="1"

# 资源参数默认值（可选：不给也可）
# SPARK_EXECUTOR_MEMORY="1g"
# SPARK_EXECUTOR_CORES="1"
# SPARK_EXECUTOR_INSTANCES="2"
# SPARK_DRIVER_MEMORY="1g"
